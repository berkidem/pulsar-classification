{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from /input/train.csv\n",
    "data = pd.read_csv(\"merged_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['Class'], axis=1) #'id'\n",
    "y = data['Class']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Val, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "     X, y, test_size=0.1, random_state=42)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     X_train, y_train, test_size=0.11, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 0\n",
      "[0]\ttrain-logloss:0.63714\tval-logloss:0.63704\n",
      "[10]\ttrain-logloss:0.31112\tval-logloss:0.31038\n",
      "[20]\ttrain-logloss:0.17331\tval-logloss:0.17264\n",
      "[30]\ttrain-logloss:0.10694\tval-logloss:0.10625\n",
      "[40]\ttrain-logloss:0.07282\tval-logloss:0.07227\n",
      "[50]\ttrain-logloss:0.05536\tval-logloss:0.05497\n",
      "[60]\ttrain-logloss:0.04589\tval-logloss:0.04568\n",
      "[70]\ttrain-logloss:0.04078\tval-logloss:0.04073\n",
      "[80]\ttrain-logloss:0.03807\tval-logloss:0.03826\n",
      "[90]\ttrain-logloss:0.03651\tval-logloss:0.03690\n",
      "[100]\ttrain-logloss:0.03554\tval-logloss:0.03612\n",
      "[110]\ttrain-logloss:0.03482\tval-logloss:0.03559\n",
      "[120]\ttrain-logloss:0.03435\tval-logloss:0.03539\n",
      "[130]\ttrain-logloss:0.03397\tval-logloss:0.03527\n",
      "[140]\ttrain-logloss:0.03366\tval-logloss:0.03515\n",
      "[150]\ttrain-logloss:0.03330\tval-logloss:0.03500\n",
      "[160]\ttrain-logloss:0.03300\tval-logloss:0.03485\n",
      "[170]\ttrain-logloss:0.03270\tval-logloss:0.03483\n",
      "[180]\ttrain-logloss:0.03247\tval-logloss:0.03477\n",
      "[190]\ttrain-logloss:0.03218\tval-logloss:0.03467\n",
      "[200]\ttrain-logloss:0.03193\tval-logloss:0.03458\n",
      "[210]\ttrain-logloss:0.03168\tval-logloss:0.03459\n",
      "[214]\ttrain-logloss:0.03162\tval-logloss:0.03460\n",
      "Fold: 1\n",
      "[0]\ttrain-logloss:0.63716\tval-logloss:0.63693\n",
      "[10]\ttrain-logloss:0.31129\tval-logloss:0.30980\n",
      "[20]\ttrain-logloss:0.17358\tval-logloss:0.17150\n",
      "[30]\ttrain-logloss:0.10717\tval-logloss:0.10488\n",
      "[40]\ttrain-logloss:0.07307\tval-logloss:0.07065\n",
      "[50]\ttrain-logloss:0.05560\tval-logloss:0.05304\n",
      "[60]\ttrain-logloss:0.04616\tval-logloss:0.04360\n",
      "[70]\ttrain-logloss:0.04105\tval-logloss:0.03863\n",
      "[80]\ttrain-logloss:0.03833\tval-logloss:0.03605\n",
      "[90]\ttrain-logloss:0.03678\tval-logloss:0.03475\n",
      "[100]\ttrain-logloss:0.03578\tval-logloss:0.03400\n",
      "[110]\ttrain-logloss:0.03507\tval-logloss:0.03350\n",
      "[120]\ttrain-logloss:0.03454\tval-logloss:0.03329\n",
      "[130]\ttrain-logloss:0.03414\tval-logloss:0.03312\n",
      "[140]\ttrain-logloss:0.03375\tval-logloss:0.03296\n",
      "[150]\ttrain-logloss:0.03341\tval-logloss:0.03288\n",
      "[160]\ttrain-logloss:0.03312\tval-logloss:0.03278\n",
      "[170]\ttrain-logloss:0.03282\tval-logloss:0.03269\n",
      "[180]\ttrain-logloss:0.03254\tval-logloss:0.03266\n",
      "[190]\ttrain-logloss:0.03227\tval-logloss:0.03259\n",
      "[200]\ttrain-logloss:0.03201\tval-logloss:0.03256\n",
      "[206]\ttrain-logloss:0.03187\tval-logloss:0.03255\n",
      "Fold: 2\n",
      "[0]\ttrain-logloss:0.63716\tval-logloss:0.63692\n",
      "[10]\ttrain-logloss:0.31143\tval-logloss:0.30951\n",
      "[20]\ttrain-logloss:0.17376\tval-logloss:0.17077\n",
      "[30]\ttrain-logloss:0.10747\tval-logloss:0.10355\n",
      "[40]\ttrain-logloss:0.07340\tval-logloss:0.06888\n",
      "[50]\ttrain-logloss:0.05595\tval-logloss:0.05093\n",
      "[60]\ttrain-logloss:0.04651\tval-logloss:0.04113\n",
      "[70]\ttrain-logloss:0.04140\tval-logloss:0.03590\n",
      "[80]\ttrain-logloss:0.03869\tval-logloss:0.03311\n",
      "[90]\ttrain-logloss:0.03711\tval-logloss:0.03162\n",
      "[100]\ttrain-logloss:0.03615\tval-logloss:0.03076\n",
      "[110]\ttrain-logloss:0.03544\tval-logloss:0.03020\n",
      "[120]\ttrain-logloss:0.03494\tval-logloss:0.02990\n",
      "[130]\ttrain-logloss:0.03455\tval-logloss:0.02970\n",
      "[140]\ttrain-logloss:0.03419\tval-logloss:0.02953\n",
      "[150]\ttrain-logloss:0.03383\tval-logloss:0.02940\n",
      "[160]\ttrain-logloss:0.03352\tval-logloss:0.02932\n",
      "[170]\ttrain-logloss:0.03323\tval-logloss:0.02926\n",
      "[176]\ttrain-logloss:0.03308\tval-logloss:0.02927\n",
      "Fold: 3\n",
      "[0]\ttrain-logloss:0.63719\tval-logloss:0.63687\n",
      "[10]\ttrain-logloss:0.31148\tval-logloss:0.30880\n",
      "[20]\ttrain-logloss:0.17383\tval-logloss:0.16984\n",
      "[30]\ttrain-logloss:0.10753\tval-logloss:0.10249\n",
      "[40]\ttrain-logloss:0.07352\tval-logloss:0.06763\n",
      "[50]\ttrain-logloss:0.05604\tval-logloss:0.04962\n",
      "[60]\ttrain-logloss:0.04660\tval-logloss:0.03978\n",
      "[70]\ttrain-logloss:0.04152\tval-logloss:0.03452\n",
      "[80]\ttrain-logloss:0.03881\tval-logloss:0.03180\n",
      "[90]\ttrain-logloss:0.03725\tval-logloss:0.03027\n",
      "[100]\ttrain-logloss:0.03628\tval-logloss:0.02942\n",
      "[110]\ttrain-logloss:0.03564\tval-logloss:0.02895\n",
      "[120]\ttrain-logloss:0.03515\tval-logloss:0.02871\n",
      "[130]\ttrain-logloss:0.03473\tval-logloss:0.02858\n",
      "[140]\ttrain-logloss:0.03434\tval-logloss:0.02845\n",
      "[150]\ttrain-logloss:0.03395\tval-logloss:0.02839\n",
      "[160]\ttrain-logloss:0.03359\tval-logloss:0.02831\n",
      "[170]\ttrain-logloss:0.03321\tval-logloss:0.02821\n",
      "[180]\ttrain-logloss:0.03298\tval-logloss:0.02815\n",
      "[190]\ttrain-logloss:0.03268\tval-logloss:0.02811\n",
      "[200]\ttrain-logloss:0.03241\tval-logloss:0.02809\n",
      "[206]\ttrain-logloss:0.03230\tval-logloss:0.02811\n",
      "Fold: 4\n",
      "[0]\ttrain-logloss:0.63718\tval-logloss:0.63696\n",
      "[10]\ttrain-logloss:0.31136\tval-logloss:0.30958\n",
      "[20]\ttrain-logloss:0.17370\tval-logloss:0.17096\n",
      "[30]\ttrain-logloss:0.10737\tval-logloss:0.10396\n",
      "[40]\ttrain-logloss:0.07328\tval-logloss:0.06938\n",
      "[50]\ttrain-logloss:0.05581\tval-logloss:0.05155\n",
      "[60]\ttrain-logloss:0.04637\tval-logloss:0.04181\n",
      "[70]\ttrain-logloss:0.04128\tval-logloss:0.03661\n",
      "[80]\ttrain-logloss:0.03858\tval-logloss:0.03385\n",
      "[90]\ttrain-logloss:0.03706\tval-logloss:0.03233\n",
      "[100]\ttrain-logloss:0.03608\tval-logloss:0.03142\n",
      "[110]\ttrain-logloss:0.03537\tval-logloss:0.03085\n",
      "[120]\ttrain-logloss:0.03484\tval-logloss:0.03051\n",
      "[130]\ttrain-logloss:0.03445\tval-logloss:0.03034\n",
      "[140]\ttrain-logloss:0.03403\tval-logloss:0.03017\n",
      "[150]\ttrain-logloss:0.03371\tval-logloss:0.03008\n",
      "[160]\ttrain-logloss:0.03344\tval-logloss:0.03001\n",
      "[170]\ttrain-logloss:0.03315\tval-logloss:0.02994\n",
      "[180]\ttrain-logloss:0.03290\tval-logloss:0.02990\n",
      "[190]\ttrain-logloss:0.03257\tval-logloss:0.02986\n",
      "[200]\ttrain-logloss:0.03234\tval-logloss:0.02982\n",
      "[210]\ttrain-logloss:0.03210\tval-logloss:0.02975\n",
      "[220]\ttrain-logloss:0.03189\tval-logloss:0.02972\n",
      "[230]\ttrain-logloss:0.03162\tval-logloss:0.02964\n",
      "[240]\ttrain-logloss:0.03139\tval-logloss:0.02960\n",
      "[250]\ttrain-logloss:0.03120\tval-logloss:0.02956\n",
      "[260]\ttrain-logloss:0.03099\tval-logloss:0.02956\n",
      "[262]\ttrain-logloss:0.03097\tval-logloss:0.02954\n",
      "Fold: 5\n",
      "[0]\ttrain-logloss:0.63717\tval-logloss:0.63688\n",
      "[10]\ttrain-logloss:0.31139\tval-logloss:0.30932\n",
      "[20]\ttrain-logloss:0.17369\tval-logloss:0.17075\n",
      "[30]\ttrain-logloss:0.10734\tval-logloss:0.10383\n",
      "[40]\ttrain-logloss:0.07322\tval-logloss:0.06952\n",
      "[50]\ttrain-logloss:0.05571\tval-logloss:0.05203\n",
      "[60]\ttrain-logloss:0.04628\tval-logloss:0.04255\n",
      "[70]\ttrain-logloss:0.04117\tval-logloss:0.03766\n",
      "[80]\ttrain-logloss:0.03841\tval-logloss:0.03513\n",
      "[90]\ttrain-logloss:0.03684\tval-logloss:0.03389\n",
      "[100]\ttrain-logloss:0.03586\tval-logloss:0.03319\n",
      "[110]\ttrain-logloss:0.03514\tval-logloss:0.03282\n",
      "[120]\ttrain-logloss:0.03463\tval-logloss:0.03264\n",
      "[130]\ttrain-logloss:0.03424\tval-logloss:0.03256\n",
      "[140]\ttrain-logloss:0.03387\tval-logloss:0.03256\n",
      "[150]\ttrain-logloss:0.03356\tval-logloss:0.03250\n",
      "[160]\ttrain-logloss:0.03325\tval-logloss:0.03241\n",
      "[170]\ttrain-logloss:0.03294\tval-logloss:0.03230\n",
      "[180]\ttrain-logloss:0.03265\tval-logloss:0.03222\n",
      "[190]\ttrain-logloss:0.03235\tval-logloss:0.03218\n",
      "[200]\ttrain-logloss:0.03211\tval-logloss:0.03214\n",
      "[210]\ttrain-logloss:0.03186\tval-logloss:0.03210\n",
      "[220]\ttrain-logloss:0.03165\tval-logloss:0.03212\n",
      "[230]\ttrain-logloss:0.03138\tval-logloss:0.03202\n",
      "[240]\ttrain-logloss:0.03124\tval-logloss:0.03204\n",
      "[241]\ttrain-logloss:0.03122\tval-logloss:0.03203\n",
      "Fold: 6\n",
      "[0]\ttrain-logloss:0.63717\tval-logloss:0.63695\n",
      "[10]\ttrain-logloss:0.31132\tval-logloss:0.30975\n",
      "[20]\ttrain-logloss:0.17361\tval-logloss:0.17148\n",
      "[30]\ttrain-logloss:0.10722\tval-logloss:0.10482\n",
      "[40]\ttrain-logloss:0.07312\tval-logloss:0.07058\n",
      "[50]\ttrain-logloss:0.05566\tval-logloss:0.05308\n",
      "[60]\ttrain-logloss:0.04622\tval-logloss:0.04347\n",
      "[70]\ttrain-logloss:0.04113\tval-logloss:0.03828\n",
      "[80]\ttrain-logloss:0.03844\tval-logloss:0.03564\n",
      "[90]\ttrain-logloss:0.03690\tval-logloss:0.03419\n",
      "[100]\ttrain-logloss:0.03595\tval-logloss:0.03332\n",
      "[110]\ttrain-logloss:0.03527\tval-logloss:0.03267\n",
      "[120]\ttrain-logloss:0.03478\tval-logloss:0.03225\n",
      "[130]\ttrain-logloss:0.03438\tval-logloss:0.03201\n",
      "[140]\ttrain-logloss:0.03400\tval-logloss:0.03178\n",
      "[150]\ttrain-logloss:0.03366\tval-logloss:0.03163\n",
      "[160]\ttrain-logloss:0.03336\tval-logloss:0.03145\n",
      "[170]\ttrain-logloss:0.03304\tval-logloss:0.03136\n",
      "[180]\ttrain-logloss:0.03277\tval-logloss:0.03126\n",
      "[190]\ttrain-logloss:0.03246\tval-logloss:0.03118\n",
      "[200]\ttrain-logloss:0.03214\tval-logloss:0.03109\n",
      "[210]\ttrain-logloss:0.03190\tval-logloss:0.03106\n",
      "[220]\ttrain-logloss:0.03173\tval-logloss:0.03104\n",
      "[230]\ttrain-logloss:0.03157\tval-logloss:0.03101\n",
      "[240]\ttrain-logloss:0.03142\tval-logloss:0.03097\n",
      "[250]\ttrain-logloss:0.03115\tval-logloss:0.03091\n",
      "[260]\ttrain-logloss:0.03098\tval-logloss:0.03092\n",
      "[270]\ttrain-logloss:0.03076\tval-logloss:0.03090\n",
      "[280]\ttrain-logloss:0.03050\tval-logloss:0.03088\n",
      "[290]\ttrain-logloss:0.03033\tval-logloss:0.03085\n",
      "[300]\ttrain-logloss:0.03020\tval-logloss:0.03083\n",
      "[305]\ttrain-logloss:0.03011\tval-logloss:0.03083\n",
      "Fold: 7\n",
      "[0]\ttrain-logloss:0.63717\tval-logloss:0.63696\n",
      "[10]\ttrain-logloss:0.31137\tval-logloss:0.30966\n",
      "[20]\ttrain-logloss:0.17369\tval-logloss:0.17112\n",
      "[30]\ttrain-logloss:0.10736\tval-logloss:0.10419\n",
      "[40]\ttrain-logloss:0.07327\tval-logloss:0.06976\n",
      "[50]\ttrain-logloss:0.05581\tval-logloss:0.05209\n",
      "[60]\ttrain-logloss:0.04635\tval-logloss:0.04253\n",
      "[70]\ttrain-logloss:0.04121\tval-logloss:0.03743\n",
      "[80]\ttrain-logloss:0.03849\tval-logloss:0.03484\n",
      "[90]\ttrain-logloss:0.03690\tval-logloss:0.03342\n",
      "[100]\ttrain-logloss:0.03591\tval-logloss:0.03265\n",
      "[110]\ttrain-logloss:0.03524\tval-logloss:0.03225\n",
      "[120]\ttrain-logloss:0.03471\tval-logloss:0.03200\n",
      "[130]\ttrain-logloss:0.03434\tval-logloss:0.03184\n",
      "[140]\ttrain-logloss:0.03399\tval-logloss:0.03171\n",
      "[150]\ttrain-logloss:0.03359\tval-logloss:0.03157\n",
      "[160]\ttrain-logloss:0.03330\tval-logloss:0.03149\n",
      "[170]\ttrain-logloss:0.03300\tval-logloss:0.03142\n",
      "[180]\ttrain-logloss:0.03272\tval-logloss:0.03138\n",
      "[190]\ttrain-logloss:0.03246\tval-logloss:0.03133\n",
      "[200]\ttrain-logloss:0.03222\tval-logloss:0.03134\n",
      "[210]\ttrain-logloss:0.03201\tval-logloss:0.03131\n",
      "[220]\ttrain-logloss:0.03177\tval-logloss:0.03126\n",
      "[230]\ttrain-logloss:0.03152\tval-logloss:0.03118\n",
      "[240]\ttrain-logloss:0.03133\tval-logloss:0.03114\n",
      "[250]\ttrain-logloss:0.03116\tval-logloss:0.03111\n",
      "[260]\ttrain-logloss:0.03098\tval-logloss:0.03113\n",
      "[262]\ttrain-logloss:0.03094\tval-logloss:0.03113\n",
      "Fold: 8\n",
      "[0]\ttrain-logloss:0.63702\tval-logloss:0.63751\n",
      "[10]\ttrain-logloss:0.31044\tval-logloss:0.31489\n",
      "[20]\ttrain-logloss:0.17235\tval-logloss:0.17941\n",
      "[30]\ttrain-logloss:0.10576\tval-logloss:0.11489\n",
      "[40]\ttrain-logloss:0.07152\tval-logloss:0.08238\n",
      "[50]\ttrain-logloss:0.05393\tval-logloss:0.06628\n",
      "[60]\ttrain-logloss:0.04444\tval-logloss:0.05812\n",
      "[70]\ttrain-logloss:0.03930\tval-logloss:0.05385\n",
      "[80]\ttrain-logloss:0.03653\tval-logloss:0.05196\n",
      "[90]\ttrain-logloss:0.03496\tval-logloss:0.05101\n",
      "[100]\ttrain-logloss:0.03397\tval-logloss:0.05047\n",
      "[110]\ttrain-logloss:0.03330\tval-logloss:0.05011\n",
      "[120]\ttrain-logloss:0.03280\tval-logloss:0.04984\n",
      "[130]\ttrain-logloss:0.03238\tval-logloss:0.04967\n",
      "[140]\ttrain-logloss:0.03200\tval-logloss:0.04951\n",
      "[150]\ttrain-logloss:0.03164\tval-logloss:0.04940\n",
      "[160]\ttrain-logloss:0.03137\tval-logloss:0.04931\n",
      "[170]\ttrain-logloss:0.03102\tval-logloss:0.04921\n",
      "[180]\ttrain-logloss:0.03073\tval-logloss:0.04907\n",
      "[190]\ttrain-logloss:0.03050\tval-logloss:0.04901\n",
      "[200]\ttrain-logloss:0.03027\tval-logloss:0.04891\n",
      "[210]\ttrain-logloss:0.03005\tval-logloss:0.04886\n",
      "[220]\ttrain-logloss:0.02984\tval-logloss:0.04884\n",
      "[230]\ttrain-logloss:0.02956\tval-logloss:0.04877\n",
      "[240]\ttrain-logloss:0.02934\tval-logloss:0.04868\n",
      "[250]\ttrain-logloss:0.02916\tval-logloss:0.04861\n",
      "[260]\ttrain-logloss:0.02889\tval-logloss:0.04856\n",
      "[270]\ttrain-logloss:0.02867\tval-logloss:0.04861\n",
      "Fold: 9\n",
      "[0]\ttrain-logloss:0.63693\tval-logloss:0.63867\n",
      "[10]\ttrain-logloss:0.30962\tval-logloss:0.32314\n",
      "[20]\ttrain-logloss:0.17112\tval-logloss:0.19100\n",
      "[30]\ttrain-logloss:0.10422\tval-logloss:0.12845\n",
      "[40]\ttrain-logloss:0.06983\tval-logloss:0.09737\n",
      "[50]\ttrain-logloss:0.05211\tval-logloss:0.08254\n",
      "[60]\ttrain-logloss:0.04254\tval-logloss:0.07594\n",
      "[70]\ttrain-logloss:0.03733\tval-logloss:0.07244\n",
      "[80]\ttrain-logloss:0.03456\tval-logloss:0.07071\n",
      "[90]\ttrain-logloss:0.03298\tval-logloss:0.07022\n",
      "[100]\ttrain-logloss:0.03199\tval-logloss:0.07002\n",
      "[110]\ttrain-logloss:0.03131\tval-logloss:0.06991\n",
      "[120]\ttrain-logloss:0.03081\tval-logloss:0.06964\n",
      "[130]\ttrain-logloss:0.03043\tval-logloss:0.06959\n",
      "[140]\ttrain-logloss:0.03005\tval-logloss:0.06950\n",
      "[150]\ttrain-logloss:0.02973\tval-logloss:0.06930\n",
      "[160]\ttrain-logloss:0.02946\tval-logloss:0.06929\n",
      "[169]\ttrain-logloss:0.02921\tval-logloss:0.06934\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "val_losses = []\n",
    "\n",
    "params = {'max_depth': 4,\n",
    "          'learning_rate': 0.06,\n",
    "          'colsample_bytree': 0.67,\n",
    "          'n_jobs': -1,\n",
    "          'objective': 'binary:logistic',\n",
    "          'early_stopping_rounds': 150,\n",
    "          'verbosity': 0,\n",
    "          'eval_metric': 'logloss'}\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(\"Fold:\", fold)\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    fit_set = xgb.DMatrix(X_train, label=y_train)\n",
    "    val_set = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    model = xgb.train(params=params, dtrain=fit_set, evals=[(fit_set, 'train'), (val_set, 'val')], num_boost_round=1000, early_stopping_rounds=10, verbose_eval=10)\n",
    "\n",
    "    val_preds = model.predict(val_set)\n",
    "    val_score = log_loss(y_val, val_preds)\n",
    "    val_losses.append(val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03660307593828035"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(val_losses)/10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter search with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial): \n",
    "    params = {\n",
    "    'task': 'train', \n",
    "    'boosting_type':'gbdt',\n",
    "    'objective':'binary',\n",
    "    'metric':'binary_logloss', \n",
    "    'verbose':-10000000,\n",
    "    'seed':42,\n",
    "    'max_bin':128,\n",
    "    'n_estimators':128,\n",
    "    # 'n_estimators':trial.suggest_int(\"n_estimators\", 800, 1200),\n",
    "    'learning_rate':0.08,\n",
    "    'feature_fraction':1.0,\n",
    "    'bagging_fraction':1.0,\n",
    "   # 'bagging_freq':trial.suggest_categorical(\"bagging_freq\", [1]),\n",
    "    'max_depth':trial.suggest_int(\"max_depth\", 5, 12), # decrease this in the next round\n",
    "    'num_leaves':trial.suggest_int(\"num_leaves\",8, 32),\n",
    "    'min_data_in_leaf':200,\n",
    "    'min_gain_to_split':1.0,\n",
    "}\n",
    "    \n",
    "    model = lgb.LGBMClassifier(**params)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=100)\n",
    "    y_val_pred = model.predict_proba(X_val)\n",
    "    logloss = log_loss(y_val, y_val_pred)\n",
    "    return logloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize');\n",
    "study.optimize(objective, n_trials=10);\n",
    "#optuna.visualization.plot_optimization_history(study)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 11, 'num_leaves': 12}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task': 'train', \n",
    "    'boosting_type':'gbdt',\n",
    "    'objective':'binary',\n",
    "    'metric':'binary_logloss', \n",
    "    'verbose':-10000000,\n",
    "    'seed':42,\n",
    "    'max_bin':128,\n",
    "    'n_estimators':128,\n",
    "    # 'n_estimators':trial.suggest_int(\"n_estimators\", 800, 1200),\n",
    "    'learning_rate':0.08,\n",
    "    'feature_fraction':1.0,\n",
    "    'bagging_fraction':1.0,\n",
    "   # 'bagging_freq':trial.suggest_categorical(\"bagging_freq\", [1]),\n",
    "    'min_data_in_leaf':200,\n",
    "    'min_gain_to_split':1.0,\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.update(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_model = lgb.LGBMClassifier(**params)\n",
    "tuned_model.fit(X_train, y_train, \n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric=['binary_logloss'],\n",
    "        early_stopping_rounds=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.030570310091813074"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = tuned_model.predict_proba(X_test)\n",
    "testloss = log_loss(y_test, preds)\n",
    "testloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.026942563847874208"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_preds = tuned_model.predict_proba(X_train)\n",
    "trainloss = log_loss(y_train, train_preds)\n",
    "trainloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03386998075382093"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds = tuned_model.predict_proba(X_val)\n",
    "valloss = log_loss(y_val, val_preds)\n",
    "valloss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the real test data from test.csv\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testtest = test_data.drop(['id'], axis=1)\n",
    "ID_test = test_data.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_testtest = poly.fit_transform(X_testtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = tuned_model.predict_proba(X_testtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.99515200e-01, 4.84800360e-04],\n",
       "       [9.99230283e-01, 7.69716583e-04],\n",
       "       [9.99826850e-01, 1.73149779e-04],\n",
       "       ...,\n",
       "       [9.99832612e-01, 1.67387506e-04],\n",
       "       [9.35309601e-01, 6.46903993e-02],\n",
       "       [1.61411435e-02, 9.83858856e-01]])"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=  preds[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.84800360e-04, 7.69716583e-04, 1.73149779e-04, ...,\n",
       "       1.67387506e-04, 6.46903993e-02, 9.83858856e-01])"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78377,)"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save test predictions to file\n",
    "submission = pd.DataFrame({'id': ID_test,\n",
    "                       'Class': preds})\n",
    "submission.to_csv('submission_optuna_lgbm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
